{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RespDiseaseCNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpySQkQ3qAyU"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Dense, Flatten, Dropout, SeparableConv1D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-h-zxhrrNu"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byk6lFsYrY4o"
      },
      "source": [
        "diagnosis_df = pd.read_csv('/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv', names=['Patient number', 'Diagnosis'])\n",
        "diagnosis_df.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tc2q2mv8v7W"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(diagnosis_df['Diagnosis'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0LtkZ0a8xEE"
      },
      "source": [
        "df_no_diagnosis = pd.read_csv('/content/gdrive/MyDrive/archive/demographic_info.txt', names = \n",
        "                 ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'],\n",
        "                 delimiter = ' ')\n",
        "df_no_diagnosis.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzaDzWor87Qr"
      },
      "source": [
        "df =  df_no_diagnosis.join(diagnosis_df.set_index('Patient number'), on = 'Patient number', how = 'left')\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpvfeZmA8-yp"
      },
      "source": [
        "root = '/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
        "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]\n",
        "def Extract_Annotation_Data(file_name, root):\n",
        "    tokens = file_name.split('_')\n",
        "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
        "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
        "    return (recording_info, recording_annotations)\n",
        "i_list = []\n",
        "rec_annotations = []\n",
        "rec_annotations_dict = {}\n",
        "for s in filenames:\n",
        "    (i,a) = Extract_Annotation_Data(s, root)\n",
        "    i_list.append(i)\n",
        "    rec_annotations.append(a)\n",
        "    rec_annotations_dict[s] = a\n",
        "recording_info = pd.concat(i_list, axis = 0)\n",
        "recording_info.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hm3HyPB9JK8"
      },
      "source": [
        "class Diagnosis():\n",
        "    def __init__ (self, id, diagnosis, image_path):\n",
        "        self.id = id\n",
        "        self.diagnosis = diagnosis \n",
        "        self.image_path = image_path   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViuRMimx9QYQ"
      },
      "source": [
        "def get_wav_files():\n",
        "    audio_path = '/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
        "    files = [f for f in listdir(audio_path) if isfile(join(audio_path, f))]  #Gets all files in dir\n",
        "    wav_files = [f for f in files if f.endswith('.wav')]  # Gets wav files \n",
        "    wav_files = sorted(wav_files)\n",
        "    return wav_files, audio_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlaLpTLp9WqY"
      },
      "source": [
        "def diagnosis_data():\n",
        "    diagnosis = pd.read_csv('/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv')\n",
        "  \n",
        "    wav_files, audio_path = get_wav_files()\n",
        "    diag_dict = { 101 : \"URTI\"}  \n",
        "    diagnosis_list = []\n",
        "  \n",
        "    for index , row in diagnosis.iterrows():\n",
        "        diag_dict[row[0]] = row[1]     \n",
        "\n",
        "    c = 0\n",
        "    for f in wav_files:\n",
        "        diagnosis_list.append(Diagnosis(c, diag_dict[int(f[:3])], audio_path+f))  \n",
        "        c+=1  \n",
        "\n",
        "    return diagnosis_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5qpuIU39iJ-"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "def audio_features(filename): \n",
        "    sound, sample_rate = sf.read(filename)\n",
        "    stft = np.abs(librosa.stft(sound))  \n",
        " \n",
        "\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=sound, sr=8000, n_mfcc=40, fmin=30).T,axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=8000).T,axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(sound, sr=8000, fmin=30).T,axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=8000, fmin=30).T,axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound), sr=sample_rate, chroma=librosa.feature.chroma_cqt(y=sound, sr=8000, fmin=30)).T,axis=0)\n",
        "    \n",
        "    concat = np.concatenate((mfccs,chroma,mel,contrast,tonnetz))\n",
        "    return concat\n",
        "\n",
        "def data_points():\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    to_hot_one = {\"COPD\":0, \"Healthy\":1, \"URTI\":2, \"Bronchiectasis\":3, \"Pneumonia\":4, \"Bronchiolitis\":5, \"Asthma\":6, \"LRTI\":7}\n",
        "\n",
        "    #count = 0\n",
        "    for f in diagnosis_data():\n",
        "        #print(count)\n",
        "        labels.append(to_hot_one[f.diagnosis]) \n",
        "        images.append(audio_features(f.image_path))\n",
        "        #count+=1\n",
        "\n",
        "    return np.array(labels), np.array(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUC-8cEk9pvm"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/filename_differences.txt'\n",
        "\n",
        "diff = pd.read_csv(path, sep=\" \", header=None, names=['file_names'])\n",
        "diff.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwtmryom9zoE"
      },
      "source": [
        "df =  diff.join(diagnosis_df,how = 'left')\n",
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYnx6Pk93lI"
      },
      "source": [
        "x = audio_features('/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/101_1b1_Al_sc_Meditron.wav')\n",
        "S = librosa.feature.melspectrogram(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMyN5q9h-AZc"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(2,2,1)\n",
        "librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
        "plt.title('URTI Mel spectrogram')\n",
        "plt.tight_layout()\n",
        "\n",
        "T = librosa.feature.mfcc(x)\n",
        "plt.subplot(2,2,2)\n",
        "librosa.display.specshow(librosa.power_to_db(T, ref=np.max))\n",
        "plt.title('URTI MFCC')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNgRuH8S-Isz"
      },
      "source": [
        "x1 = audio_features('/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/105_1b1_Tc_sc_Meditron.wav')\n",
        "S1 = librosa.feature.melspectrogram(x1)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(2,2,1)\n",
        "librosa.display.specshow(librosa.power_to_db(S1, ref=np.max))\n",
        "plt.title('COPD Mel spectrogram')\n",
        "plt.tight_layout()\n",
        "\n",
        "T1 = librosa.feature.mfcc(x1)\n",
        "plt.subplot(2,2,2)\n",
        "librosa.display.specshow(librosa.power_to_db(T1, ref=np.max))\n",
        "plt.title('COPD MFCC')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqt3476E-R9R"
      },
      "source": [
        "x2 = audio_features('/content/gdrive/MyDrive/archive/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files/104_1b1_Pl_sc_Litt3200.wav')\n",
        "S2 = librosa.feature.melspectrogram(x2)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(2,2,1)\n",
        "librosa.display.specshow(librosa.power_to_db(S2, ref=np.max))\n",
        "plt.title('Healthy Mel spectrogram')\n",
        "plt.tight_layout()\n",
        "\n",
        "T2 = librosa.feature.mfcc(x2)\n",
        "plt.subplot(2,2,2)\n",
        "librosa.display.specshow(librosa.power_to_db(T2, ref=np.max))\n",
        "plt.title('Healthy MFCC')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJlBGvoG-aqu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocessing(labels, images):    \n",
        "\n",
        "  # Remove Asthma and LRTI\n",
        "    images = np.delete(images, np.where((labels == 7) | (labels == 6))[0], axis=0) \n",
        "    labels = np.delete(labels, np.where((labels == 7) | (labels == 6))[0], axis=0)      \n",
        "\n",
        "  # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=10)\n",
        "\n",
        "  # Hot one encode the labels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)  \n",
        "\n",
        "  # Format new data\n",
        "    y_train = np.reshape(y_train, (y_train.shape[0], 6))\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    y_test = np.reshape(y_test, (y_test.shape[0], 6))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKD1_uuI-j0i"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "\n",
        "labels, images = data_points()\n",
        "X_train, X_test, y_train, y_test = preprocessing(labels, images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLYBEbVh-qVY"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(193, 1)))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))   \n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=55\n",
        "                    , batch_size=200, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEGBlm97-v23"
      },
      "source": [
        "def visualize_training(history, lw = 3):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
        "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
        "    plt.title('Training Accuracy vs Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(fontsize = 'x-large')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
        "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
        "    plt.title('Training Loss vs Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(fontsize = 'x-large')\n",
        "    plt.show()\n",
        "visualize_training(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPXFdH2y-1ki"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "matrix_index = [\"COPD\", \"Healthy\", \"URTI\", \"Bronchiectasis\", \"Pneumoina\", \"Bronchiolitis\"]\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
        "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
        "\n",
        "cm = confusion_matrix(y_testclass, classpreds)\n",
        "print(classification_report(y_testclass, classpreds, target_names=matrix_index))\n",
        "\n",
        "# Get percentage value for each element of the matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "cm_perc = cm / cm_sum.astype(float) * 100\n",
        "annot = np.empty_like(cm).astype(str)\n",
        "nrows, ncols = cm.shape\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        c = cm[i, j]\n",
        "        p = cm_perc[i, j]\n",
        "        if i == j:\n",
        "            s = cm_sum[i]\n",
        "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "        elif c == 0:\n",
        "            annot[i, j] = ''\n",
        "        else:\n",
        "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "\n",
        "\n",
        "# Display confusion matrix \n",
        "df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(df_cm, annot=annot, fmt='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSphDYS6--87"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GKrrb_Ki7Do"
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/Jan21RespModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}